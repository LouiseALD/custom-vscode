
import os
import json
import subprocess
import platform
from pathlib import Path

# Lista de extens√µes que ser√£o instaladas
extensions = [
    "esbenp.prettier-vscode",
    "dbaeumer.vscode-eslint",
    "eamodio.gitlens",
    "pkief.material-icon-theme",
    "ms-python.python",
    "ms-toolsai.jupyter",
    "ritwickdey.LiveServer"
]

# Fun√ß√£o para instalar extens√µes
def install_extensions():
    print("üîß Instalando extens√µes...")
    for ext in extensions:
        try:
            subprocess.run(["code", "--install-extension", ext, "--force"], check=True)
            print(f"‚úÖ {ext} instalada com sucesso.")
        except subprocess.CalledProcessError:
            print(f"‚ùå Falha ao instalar {ext}.")

# Fun√ß√£o para encontrar o caminho do settings.json
def get_settings_path():
    system = platform.system()
    if system == "Windows":
        base = os.getenv("APPDATA")
        return Path(base) / "Code" / "User" / "settings.json"
    elif system == "Darwin":  # macOS
        return Path.home() / "Library" / "Application Support" / "Code" / "User" / "settings.json"
    else:  # Linux
        return Path.home() / ".config" / "Code" / "User" / "settings.json"

# Fun√ß√£o para atualizar settings.json
def update_settings():
    settings_path = get_settings_path()
    settings = {}

    if settings_path.exists():
        with open(settings_path, "r", encoding="utf-8") as f:
            try:
                settings = json.load(f)
            except json.JSONDecodeError:
                print("‚ö†Ô∏è Arquivo settings.json est√° corrompido ou vazio. Um novo ser√° criado.")

    new_settings = {
        "editor.fontSize": 14,
        "editor.tabSize": 2,
        "editor.formatOnSave": True,
        "workbench.iconTheme": "material-icon-theme",
        "workbench.colorTheme": "Default Dark+",
        "files.autoSave": "afterDelay",
        "editor.minimap.enabled": True,
        "terminal.integrated.fontSize": 13
    }

    settings.update(new_settings)

    with open(settings_path, "w", encoding="utf-8") as f:
        json.dump(settings, f, indent=2)
        print(f"‚úÖ settings.json atualizado com sucesso em {settings_path}")

# Execu√ß√£o
if __name__ == "__main__":
    print("üé® Iniciando personaliza√ß√£o do VSCode...")
    install_extensions()
    update_settings()
    print("‚ú® Tudo pronto!")


=================================================================================================

lambda_function

import os
import sys
import boto3
import json
import time

from src.json_loader import carregar_mapeamentos, buscar_por_termos, filtrar_jsons
from src.query_processor import processar_query
from src.aws_client import converter_query_oc3_para_datamesh
from src.query_validator import validar_query
from src.sac_oc3_converter import carregar_mapeamentos_sac, converter_query_sac_para_datamesh, processar_query_sac

def lambda_handler(event: dict, _context) -> dict:
    """
    Processa a query recebida no evento e retorna o resultado convertido.
    Oferece dois tipos de convers√£o:
    1. OC3 Light para DataMesh
    2. SAC para OC3 Light (e depois para DataMesh)

    :param event: Evento recebido pela fun√ß√£o Lambda, deve conter a chave `query`.
    :param _context: Contexto da execu√ß√£o da Lambda (n√£o utilizado).
    :return: Dicion√°rio com o resultado da query convertida ou mensagem de erro.
    """
    try:
        # Perguntar ao usu√°rio qual tipo de convers√£o deseja fazer PRIMEIRO
        print("\nSelecione o tipo de convers√£o:")
        print("1 - Converter query OC3 Light para DataMesh")
        print("2 - Converter SAC para OC3 Light")
        tipo_conversao = input("Digite 1 ou 2: ").strip()
        
        if tipo_conversao not in ["1", "2"]:
            return {"error": "Tipo de convers√£o inv√°lido. Por favor, selecione 1 ou 2."}
        
        # DEPOIS, receber a query do usu√°rio
        print("\nDigite ou cole sua query SQL (pressione Ctrl+Z e Enter para finalizar):")
        query = sys.stdin.read()  # ctrl+z para parar a leitura da entrada

        if not query:
            return {"error": "Nenhuma query informada"}

        # Crie uma sess√£o boto3 usando as credenciais definidas no ambiente
        session = boto3.Session(
            aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
            aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
            aws_session_token=os.getenv("AWS_SESSION_TOKEN")
        )

        bedrock_runtime = session.client("bedrock-runtime", region_name="us-east-1")
        
        # Definir caminhos para arquivos de mapeamento
        base_dir = os.path.dirname(__file__)
        json_folder_oc3 = os.path.join(base_dir, "mapeamentos-de-para")
        json_folder_sac = os.path.join(base_dir, "mapeamentos-sac")

        # Valide a query
        validacao_resultado = validar_query(query)
        if validacao_resultado["status"] != "Sucesso":
            return {"error": validacao_resultado["mensagem"]}

        print(f"\nQuery recebida: {query}")
        start_time = time.time()
        
        if tipo_conversao == "1":
            # Fluxo OC3 Light para DataMesh
            print("\nProcessando convers√£o OC3 Light para DataMesh...")
            
            # Carregar mapeamentos OC3 Light
            mapeamentos = carregar_mapeamentos(json_folder_oc3)
            resultados = buscar_por_termos(query, mapeamentos)
            resultados_filtrados = filtrar_jsons(resultados)
            
            if not resultados_filtrados:
                return {"error": "Nenhuma tabela de refer√™ncia encontrada na query."}
            
            # Verificar se tem m√∫ltiplos mapeamentos
            tem_multiplos_mapeamentos = len(resultados_filtrados) > 1
            
            if tem_multiplos_mapeamentos:
                print("\nForam encontrados m√∫ltiplos mapeamentos para esta query.")
                print("Voc√™ quer: 1 - Processar a query diretamente, 2 - Selecionar as tabelas do de-para")
                escolha = input("Selecione 1 ou 2: ").strip()
                
                if escolha == "1":
                    # Processar diretamente com o primeiro mapeamento
                    mapeamentos_usuario = [resultados_filtrados[0]]
                    print("Usando o primeiro mapeamento encontrado.")
                elif escolha == "2":
                    # Sele√ß√£o interativa de mapeamentos
                    print("\nIniciando sele√ß√£o interativa de mapeamentos...")
                    mapeamentos_usuario = processar_query(query, resultados_filtrados)
                else:
                    return {"error": "Op√ß√£o inv√°lida. Por favor, selecione 1 ou 2."}
            else:
                # Apenas um mapeamento encontrado, usar diretamente
                mapeamentos_usuario = [resultados_filtrados[0]]
                print("Apenas um mapeamento encontrado, processando diretamente.")
            
            # Converter a query
            print("\nEnviando query para convers√£o...")
            resultado = converter_query_oc3_para_datamesh(bedrock_runtime, query, mapeamentos_usuario)
            
        elif tipo_conversao == "2":
            # Fluxo SAC para OC3 Light
            print("\nProcessando convers√£o SAC para OC3 Light...")
            
            # Verificar se cont√©m tbpli_ (indicativo de query SAC)
            if "tbpli_" not in query:
                print("Aviso: Esta query n√£o parece ser do tipo SAC (n√£o cont√©m prefixo tbpli_)")
                confirmar = input("Deseja continuar mesmo assim? (S/N): ").strip().upper()
                if confirmar != "S":
                    return {"error": "Opera√ß√£o cancelada pelo usu√°rio."}
            
            # Carregar mapeamentos SAC
            mapeamentos_sac = carregar_mapeamentos_sac(json_folder_sac)
            
            if not mapeamentos_sac:
                return {"error": "Nenhum mapeamento SAC encontrado. Verifique os arquivos de mapeamento."}
            
            print(f"Mapeamentos SAC carregados: {len(mapeamentos_sac)} registros")
            
            # Analisar a query para verificar m√∫ltiplos mapeamentos
            tabelas_aliases = {}
            colunas_por_alias = {}
            tem_multiplos_mapeamentos = False
            
            try:
                from src.sac_oc3_converter import extrair_tabelas_aliases_sac, extrair_colunas_usadas_sac, compactar_mapeamentos_sac
                
                # Extrair tabelas e aliases
                tabelas_aliases = extrair_tabelas_aliases_sac(query)
                
                # Extrair colunas
                colunas_por_alias = extrair_colunas_usadas_sac(query, tabelas_aliases)
                
                # Compactar mapeamentos
                mapeamentos_compactados = compactar_mapeamentos_sac(mapeamentos_sac, tabelas_aliases, colunas_por_alias)
                
                # Verificar se tem m√∫ltiplas op√ß√µes de mapeamento
                for tabela, opcoes in mapeamentos_compactados.items():
                    if len(opcoes) > 1:
                        tem_multiplos_mapeamentos = True
                        break
            except Exception as e:
                print(f"Aviso: Erro ao analisar m√∫ltiplos mapeamentos: {str(e)}")
                tem_multiplos_mapeamentos = True  # Assume que h√° m√∫ltiplos para seguran√ßa
            
            if tem_multiplos_mapeamentos:
                print("\nForam encontrados m√∫ltiplos mapeamentos para esta query.")
                print("Voc√™ quer: 1 - Processar a query diretamente, 2 - Selecionar as tabelas do de-para")
                escolha = input("Selecione 1 ou 2: ").strip()
                
                if escolha == "1":
                    # Processar diretamente
                    print("Processando a query diretamente...")
                    resultado = converter_query_sac_para_datamesh(bedrock_runtime, query, mapeamentos_sac, modo_automatico=True)
                elif escolha == "2":
                    # Sele√ß√£o interativa
                    print("\nIniciando sele√ß√£o interativa de mapeamentos...")
                    mapeamentos_selecionados = processar_query_sac(query, mapeamentos_sac)
                    print("Enviando query para convers√£o com mapeamentos selecionados...")
                    resultado = converter_query_sac_para_datamesh(bedrock_runtime, query, mapeamentos_selecionados, modo_automatico=True)
                else:
                    return {"error": "Op√ß√£o inv√°lida. Por favor, selecione 1 ou 2."}
            else:
                # Apenas um mapeamento encontrado, usar diretamente
                print("Processando a query diretamente...")
                resultado = converter_query_sac_para_datamesh(bedrock_runtime, query, mapeamentos_sac, modo_automatico=True)
        
        end_time = time.time()
        total_time = end_time - start_time
        print(f"Tempo total de execu√ß√£o: {total_time:.2f} segundos")

        print("\nQuery convertida:")
        print(resultado)
        return resultado

    except Exception as e:
        return {"error": f"Erro interno ao processar a query: {str(e)}"}

if __name__ == "__main__":
    query_convertida = lambda_handler(None, None)
    print(query_convertida)

=================================================================================================
aws_client

import json
import logging
from typing import List, Dict
import time

def calcular_max_tokens(json_mappings: List[Dict]) -> int:
    """Calcula o n√∫mero m√°ximo de tokens baseado nos mapeamentos JSON fornecidos.

    :param json_mappings: Lista de dicion√°rios contendo mapeamentos JSON.
    :return: N√∫mero m√°ximo de tokens calculado.
    """
    # Calcula o tamanho aproximado dos mapeamentos
    json_str = json.dumps(json_mappings)
    tamanho_bytes = len(json_str.encode('utf-8'))
    
    # Estimativa de tokens (aproximadamente 4 caracteres por token)
    tokens_estimados = tamanho_bytes / 4
    
    # Tokens base para o prompt e a resposta
    base_tokens = 500
    # Adicionar tokens para o mapeamento
    dynamic_tokens = tokens_estimados * 1.2  # Margem de seguran√ßa de 20%
    
    # Limitar a um m√°ximo razo√°vel
    max_tokens = min(2500, base_tokens + int(dynamic_tokens))
    
    print(f"Estimativa de tokens para mapeamentos: {int(tokens_estimados)}")
    print(f"Total de tokens alocados: {max_tokens}")
    
    return max_tokens

def preparar_mapeamentos_para_bedrock(json_mappings: List[Dict]) -> List[Dict]:
    """
    Prepara os mapeamentos para envio ao Bedrock, simplificando a estrutura se necess√°rio.
    
    :param json_mappings: Lista de dicion√°rios contendo mapeamentos JSON.
    :return: Lista de mapeamentos preparados para envio.
    """
    # Se os mapeamentos estiverem vazios, retornar uma lista vazia
    if not json_mappings:
        print("AVISO: Mapeamentos vazios recebidos para prepara√ß√£o")
        return []
        
    mapeamentos_preparados = []
    
    # Para cada mapeamento na lista
    for mapeamento in json_mappings:
        mapeamento_simplificado = {}
        
        # Para cada tabela no mapeamento
        for tabela, colunas in mapeamento.items():
            if isinstance(colunas, dict):
                tabela_info = {}
                
                # Para cada coluna nas colunas da tabela
                for coluna, info in colunas.items():
                    # Se a informa√ß√£o for um dicion√°rio, extrair os campos relevantes
                    if isinstance(info, dict):
                        tabela_info[coluna] = {
                            "tabela_origem": tabela,
                            "tabela_destino": info.get("tabela_data_mesh", ""),
                            "coluna_destino": info.get("campo_data_mesh", ""),
                            "tipo_dado": info.get("tipo_de_dado", ""),
                            "tipo": info.get("tipo", "")
                        }
                    else:
                        # Se a informa√ß√£o n√£o for um dicion√°rio, apenas armazenar o valor
                        tabela_info[coluna] = str(info)
                        
                mapeamento_simplificado[tabela] = tabela_info
            else:
                # Se as colunas n√£o forem um dicion√°rio, armazenar diretamente
                mapeamento_simplificado[tabela] = str(colunas)
                
        mapeamentos_preparados.append(mapeamento_simplificado)
        
    print(f"Mapeamentos preparados: {len(mapeamentos_preparados)} itens")
    return mapeamentos_preparados

def converter_query_oc3_para_datamesh(bedrock_runtime, query: str, json_mappings: List[Dict]) -> str:
    """Converte uma query SQL do padr√£o OC3 para o padr√£o Datamesh usando os mapeamentos JSON.

    :param query: Query SQL no padr√£o OC3.
    :param json_mappings: Lista de dicion√°rios contendo mapeamentos JSON.
    :return: Query SQL convertida para o padr√£o Datamesh.
    """
    try:
        # Verifica se h√° mapeamentos dispon√≠veis
        if not json_mappings:
            return "Erro: N√£o h√° mapeamentos dispon√≠veis para convers√£o"
            
        # Prepara os mapeamentos para envio ao Bedrock
        mapeamentos_preparados = preparar_mapeamentos_para_bedrock(json_mappings)
        
        if not mapeamentos_preparados:
            return "Erro: Falha ao preparar mapeamentos para envio ao Bedrock"
        
        # Print detalhado dos mapeamentos que ser√£o enviados ao Bedrock
        print("\n" + "=" * 80)
        print("MAPEAMENTOS PREPARADOS PARA ENVIO AO BEDROCK:")
        print("=" * 80)
        mapeamentos_json = json.dumps(mapeamentos_preparados, indent=2)
        # Limitar a sa√≠da para n√£o sobrecarregar o console
        if len(mapeamentos_json) > 1000:
            print(mapeamentos_json[:1000] + "... (truncado)")
        else:
            print(mapeamentos_json)
        print("=" * 80)
        
        # Atualiza o payload para usar o novo prompt e a query fornecida
        prompt = """
Voc√™ √© um assistente especializado em convers√£o de mapeamento fornecido.

INSTRU√á√ïES PARA CONVERS√ÉO DE QUERY SQL:

1. N√£o altere a l√≥gica da query.
2. Substitua apenas os nomes das tabelas e colunas conforme o mapeamento fornecido.
3. A linguagem da query ser√° SQL com o tipo Athena (AWS).
4. Utilize os mapeamentos da lista de JSON para substituir apenas os nomes de campos e tabelas do OC3 LIGHT(DE) pelos equivalentes em Datamesh.
5. N√£o altere a l√≥gica, a estrutura, os alias, os formatos etc.
6. Mantenha os alias de tabelas (exemplo: AS "A") inalterados.
7. Se a tabela for do tipo "cadastro", adicione o prefixo "spec_".
8. Se a tabela for do tipo "hub", adicione o prefixo "hub_".
9. Se a query SQL convertida n√£o possuir substitui√ß√£o, retorne inalterada.
10. Se n√£o existir tabela ou coluna no mapeamento, retorne inalterado.
11. A query deve ser retornada no padr√£o de Athena.
12. Se houver diferen√ßa de tipos de dados, utilize "CAST" para substituir.
13. Para cada campo encontrado na query, use o tipo fornecido no mapeamento.
14. Mantenha os tipos de dados corretos, sem convers√£o desnecess√°ria.
15. Ignore campos que j√° est√£o no tipo correto.
16. Lide corretamente com CTEs (WITH clauses) aplicando as mesmas regras aos nomes de tabelas e colunas nas defini√ß√µes de CTE.
17. Preserve exatamente a mesma estrutura da query, incluindo indenta√ß√£o, quebras de linha e espa√ßos.
18. Mantenha todas as express√µes como MAX(), MIN(), COUNT() intactas, apenas aplicando as convers√µes necess√°rias aos nomes de colunas dentro dessas fun√ß√µes.

FORMATO DE SA√çDA:
1. Retorne APENAS a query SQL convertida, sem explica√ß√µes adicionais.
2. N√£o inclua marcadores de c√≥digo como ```sql.
3. A resposta deve come√ßar diretamente com a instru√ß√£o SQL.
"""

        # Calcula o max_tokens baseado nos mapeamentos
        max_tokens = calcular_max_tokens(mapeamentos_preparados)

        payload = {
            "anthropic_version": "bedrock-2023-05-31",  # Certifique-se de usar a vers√£o correta
            "messages": [
                {
                    "role": "user",
                    "content": f"{prompt}\n\nQuery original (no formato OC3): {query}\n\nJSON Mapeamentos (DE-PARA): {json.dumps(mapeamentos_preparados)}"
                }
            ],
            "max_tokens": max_tokens
        }

        print("\nEnviando payload para Bedrock com m√°ximo de tokens:", max_tokens)
        start_time = time.time()

        # Faz a chamada ao modelo
        response = bedrock_runtime.invoke_model(
            modelId="anthropic.claude-3-sonnet-20240229-v1-0",  # Certifique-se de usar o ID correto do modelo
            contentType="application/json",
            accept="application/json",
            body=json.dumps(payload).encode("utf-8")
        )

        end_time = time.time()
        response_time = end_time - start_time
        print(f"Tempo de resposta da API do Bedrock: {response_time:.2f} segundos")

        # Processa a resposta
        response_body = json.loads(response["body"].read().decode("utf-8"))
        
        # Extrair a resposta do modelo
        if "content" in response_body and isinstance(response_body["content"], list) and len(response_body["content"]) > 0:
            query_convertida = response_body["content"][0].get("text", "")
            print("\nResposta bruta do Bedrock:")
            print("-" * 40)
            print(query_convertida)
            print("-" * 40)
            return query_convertida
        else:
            print("Estrutura de resposta inesperada do Bedrock:", response_body)
            return "Erro: Estrutura de resposta inesperada do Bedrock"

    except Exception as e:
        import traceback
        print("Erro ao processar a query no Bedrock:")
        print(traceback.format_exc())
        return f"Erro ao processar a query: {str(e)}"

=================================================================================================

json_loader

import re
import json
import logging
import os

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

def carregar_mapeamentos(pasta_json: str) -> list:
    """Carrega mapeamentos de arquivos JSON em uma pasta especificada.

    :param pasta_json: Caminho para a pasta contendo arquivos JSON.
    :return: Lista de dicion√°rios com mapeamentos carregados.
    """
    logger.info(f"Tentando carregar mapeamentos da pasta: {pasta_json}")
    mapeamentos = []
    
    if not os.path.exists(pasta_json):
        print(f"ERRO: Pasta {pasta_json} n√£o encontrada")
        # Tentar pastas alternativas
        alternativas = [
            os.path.join(os.getcwd(), "mapeamentos-de-para"),
            os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "mapeamentos-de-para"),
            os.path.join(os.path.dirname(os.path.abspath(__file__)), "mapeamentos-de-para")
        ]
        
        for alt in alternativas:
            if os.path.exists(alt):
                print(f"Usando pasta alternativa: {alt}")
                pasta_json = alt
                break
    
    # Lista todos os arquivos na pasta
    try:
        todos_arquivos = os.listdir(pasta_json)
        print(f"Arquivos encontrados na pasta: {todos_arquivos}")
        arquivos_json = [f for f in todos_arquivos if f.endswith('.json')]
        print(f"Arquivos JSON encontrados: {arquivos_json}")
    except Exception as e:
        print(f"Erro ao listar arquivos: {e}")
        return mapeamentos

    for root, _, files in os.walk(pasta_json):
        for file in files:
            if file.endswith(".json"):
                caminho_json = os.path.join(root, file)
                try:
                    print(f"Lendo arquivo: {caminho_json}")
                    with open(caminho_json, "r", encoding="utf-8") as f:
                        conteudo = f.read()
                        # Print dos primeiros 100 caracteres para debug
                        print(f"Primeiros 100 caracteres: {conteudo[:100]}")
                        dados = json.loads(conteudo)
                        if isinstance(dados, list):
                            for item in dados:
                                if isinstance(item, dict):
                                    mapeamentos.append(item)
                            print(f"Carregados {len(dados)} itens do arquivo {file}")
                        else:
                            print(f"AVISO: Arquivo {file} n√£o cont√©m uma lista JSON")
                except Exception as e:
                    print(f"Erro ao processar o arquivo {caminho_json}: {e}")

    print(f"Total de mapeamentos carregados: {len(mapeamentos)}")
    return mapeamentos

def extrair_elementos_query(query):
    """
    Extrai tabelas e campos de uma query SQL de forma mais robusta,
    incluindo suporte para CTEs e subconsultas.
    """
    # Padronizar query para facilitar a extra√ß√£o
    query_normalizada = re.sub(r'\s+', ' ', query).upper()
    
    # Extrair CTEs
    cte_pattern = r'WITH\s+(\w+)\s+AS\s*\('
    ctes = re.findall(cte_pattern, query_normalizada, re.IGNORECASE)
    
    # Extrair tabelas da cl√°usula FROM
    from_pattern = r'FROM\s+([A-Za-z0-9_\.]+)'
    tabelas_from = re.findall(from_pattern, query_normalizada, re.IGNORECASE)
    
    # Extrair tabelas da cl√°usula JOIN
    join_pattern = r'JOIN\s+([A-Za-z0-9_\.]+)'
    tabelas_join = re.findall(join_pattern, query_normalizada, re.IGNORECASE)
    
    # Juntar todas as tabelas
    todas_tabelas = ctes + tabelas_from + tabelas_join
    
    # Remover prefixos de esquema (exemplo: dbo.)
    tabelas_limpas = []
    for tabela in todas_tabelas:
        if '.' in tabela:
            partes = tabela.split('.')
            tabelas_limpas.append(partes[-1])
        else:
            tabelas_limpas.append(tabela)
    
    # Extrair campos
    # Primeiro, pegar todos os SELECT at√© o primeiro FROM
    select_clauses = re.findall(r'SELECT(.*?)FROM', query_normalizada, re.IGNORECASE | re.DOTALL)
    
    # Extrair nome dos campos
    campos = []
    for clause in select_clauses:
        # Se contiver "*" adicionar como um campo especial
        if "*" in clause:
            campos.append("*")
            
        # Extrair campo.coluna
        campo_coluna = re.findall(r'([A-Za-z0-9_]+)\.([A-Za-z0-9_]+)', clause)
        for _, col in campo_coluna:
            campos.append(col)
            
        # Extrair campos isolados (sem alias)
        campos_isolados = re.findall(r'(?:,|\s)([A-Za-z][A-Za-z0-9_]*)', clause)
        campos.extend(campos_isolados)
    
    # Remover duplicatas
    tabelas_unicas = list(set(tabelas_limpas))
    campos_unicos = list(set(campos))
    
    return {
        'tabelas': tabelas_unicas,
        'campos': campos_unicos
    }

def buscar_por_termos(query, mapeamentos):
    """
    Busca por termos da query nos mapeamentos fornecidos.
    Melhorado para ser mais flex√≠vel na correspond√™ncia.
    """
    # Extrair elementos da query
    elementos_query = extrair_elementos_query(query)
    
    print("\n" + "=" * 50)
    print(f"QUERY ORIGINAL: {query}")
    print(f"Tabelas extra√≠das: {elementos_query['tabelas']}")
    print(f"Campos extra√≠dos: {elementos_query['campos']}")
    print(f"Total de mapeamentos: {len(mapeamentos)}")

    resultados = []

    # Iterar sobre todos os mapeamentos
    for item in mapeamentos:
        # Verificar correspond√™ncia de tabela
        tabela_oc3 = item.get("TABELA OC3 LIGHT", "").upper()
        
        # Correspond√™ncia de tabela: verificar se alguma tabela da query corresponde
        tabela_match = False
        for tabela_query in elementos_query['tabelas']:
            # Correspond√™ncia direta ou parcial
            if (tabela_oc3 == tabela_query or 
                tabela_oc3 in tabela_query or 
                tabela_query in tabela_oc3 or
                # Correspond√™ncia com parte do nome (ap√≥s remover prefixos comuns)
                tabela_oc3.replace("TBOC3_", "") in tabela_query or
                tabela_query in tabela_oc3.replace("TBOC3_", "")):
                tabela_match = True
                break

        # Se n√£o encontrou tabela, continue
        if not tabela_match:
            continue

        # Verificar campos
        campo_oc3 = item.get("CAMPO OC3 LIGHT", "").upper()
        
        # Flag para indicar se houve correspond√™ncia de campo
        campo_match = False
        campos_correspondentes = []
        
        for campo_query in elementos_query['campos']:
            # Normalizar para compara√ß√£o (remover espa√ßos, converter para mai√∫sculas)
            campo_query_norm = campo_query.strip().upper()
            
            # Compara√ß√µes mais flex√≠veis
            if (campo_query_norm == campo_oc3 or 
                campo_oc3 in campo_query_norm or 
                campo_query_norm in campo_oc3):
                campo_match = True
                campos_correspondentes.append(campo_query)

        # Se o campo da query for "*" (select *), consideramos que h√° correspond√™ncia
        if "*" in elementos_query['campos']:
            campo_match = True
            campos_correspondentes.append("*")
            
        # Se encontrou campos correspondentes ou o campo √© "*", adicionar o item
        if campo_match or "*" in elementos_query['campos']:
            novo_item = {
                "tipo": item.get("tipo", ""),
                "TABELA OC3 LIGHT": item.get("TABELA OC3 LIGHT", ""),
                "TABELA DATA MESH": item.get("TABELA DATA MESH", ""),
                "CAMPO OC3 LIGHT": item.get("CAMPO OC3 LIGHT", ""),
                "CAMPO DATA MESH FINAL": item.get("CAMPO DATA MESH FINAL", ""),
                "TIPO DE DADO": item.get("TIPO DE DADO", ""),
                "campos_match": campos_correspondentes
            }
            resultados.append(novo_item)
            print(f"Item adicionado aos resultados: {item.get('TABELA OC3 LIGHT', '')}.{item.get('CAMPO OC3 LIGHT', '')}")

    # Debug final
    print(f"\nResultados encontrados: {len(resultados)}")
    return resultados

def filtrar_jsons(resultados: list) -> list:
    """Filtra resultados JSON para incluir apenas itens com campos v√°lidos.

    :param resultados: Lista de dicion√°rios a serem filtrados.
    :return: Lista de dicion√°rios filtrados.
    """
    
    resultados_filtrados = [
        {
            "tipo": item.get("tipo"),
            "TABELA OC3 LIGHT": item.get("TABELA OC3 LIGHT"),
            "CAMPO OC3 LIGHT": item.get("CAMPO OC3 LIGHT"),
            "TABELA DATA MESH": item.get("TABELA DATA MESH"),
            "CAMPO DATA MESH FINAL": item.get("CAMPO DATA MESH FINAL"),
            "TIPO DE DADO": item.get("TIPO DE DADO")
        }
        for item in resultados
        if item.get("tipo") != "nan"
        and item.get("TABELA OC3 LIGHT") != "nan"
        and item.get("CAMPO OC3 LIGHT") != "nan"
        and item.get("TABELA DATA MESH") != "nan"
        and item.get("CAMPO DATA MESH FINAL") != "nan"
        and item.get("TIPO DE DADO") != "nan"
    ]
    
    # Debug - imprimir informa√ß√µes sobre os resultados filtrados
    print(f"Total de mapeamentos carregados: {len(resultados)}")
    if resultados_filtrados:
        print(f"Primeiros 3 mapeamentos: {resultados_filtrados[:3]}")
    else:
        print("ATEN√á√ÉO: Nenhum mapeamento filtrado dispon√≠vel!")
    
    return resultados_filtrados

=================================================================================================

query_processor

import re

def extrair_tabelas_aliases(query):
    """
    Extrai tabelas e aliases de uma query SQL, incluindo suporte para CTEs (WITH clauses).
    Retorna um dicion√°rio onde as chaves s√£o os aliases e os valores s√£o os nomes das tabelas.
    """
    # Dicion√°rio para armazenar os pares alias:tabela
    tabela_alias_dict = {}
    
    # 1. Extrair as CTEs (WITH clauses)
    cte_pattern = r"(\w+)\s+as\s*\(\s*select"
    cte_matches = re.findall(cte_pattern, query, re.IGNORECASE)
    
    # Adicionar as CTEs como tabelas virtuais (o alias √© o pr√≥prio nome da CTE)
    for cte_name in cte_matches:
        tabela_alias_dict[cte_name.lower()] = cte_name.lower()
    
    # 2. Capturar tabelas e aliases na cl√°usula FROM principal e JOINs
    # Padr√£o para "FROM tabela [AS] alias" ou "JOIN tabela [AS] alias"
    table_pattern = r"(?:FROM|JOIN)\s+(\w+(?:\.\w+)?)\s+(?:AS\s+)?(\w+)"
    table_matches = re.findall(table_pattern, query, re.IGNORECASE)
    
    # Processar os matches da cl√°usula FROM/JOIN
    for table, alias in table_matches:
        if alias and table:
            # Remover prefixos de schema se existirem (como "dbo.")
            if "." in table:
                _, table = table.split(".", 1)
            tabela_alias_dict[alias.lower()] = table.upper()
    
    # Imprime para debug
    print(f"Tabelas e aliases extra√≠dos: {tabela_alias_dict}")
    
    return tabela_alias_dict

def extrair_colunas_usadas(query, resultados_filtrados):
    colunas_usadas = {}

    # Capturar refer√™ncias de coluna no formato "alias.coluna"
    matches = re.findall(r"(\w+)\.(\w+)", query)
    # Converter aliases para lowercase para uniformidade
    matches = [(a.lower(), b.lower()) for (a, b) in matches]

    for alias, coluna in matches:
        if alias not in colunas_usadas:
            colunas_usadas[alias] = set()
        colunas_usadas[alias].add(coluna)

    # Capturar colunas isoladas (sem alias)
    # Ignorando palavras-chave SQL comuns
    colunas_isoladas = re.findall(r"\b(\w+)\b", query)
    palavras_reservadas = {"SELECT", "FROM", "JOIN", "ON", "WHERE", "ORDER", "BY", "HAVING", "GROUP", 
                          "CASE", "WHEN", "THEN", "ELSE", "END", "AS", "WITH", "BETWEEN", "AND", "OR",
                          "NOT", "LIKE", "IN", "EXISTS", "DISTINCT", "UNION", "ALL"}

    for coluna in colunas_isoladas:
        if coluna.upper() not in palavras_reservadas and not coluna.isdigit():
            if "sem_alias" not in colunas_usadas:
                colunas_usadas["sem_alias"] = set()
            colunas_usadas["sem_alias"].add(coluna.upper())

    # Debug
    print("Colunas agrupadas por alias:")
    for alias, cols in colunas_usadas.items():
        print(f"  {alias}: {cols}")
        
    return colunas_usadas

def compactar_json(resultados_filtrados, tabelas_query, colunas_query):
    """
    Compacta os resultados filtrados em um formato mais eficiente para processamento.
    """
    json_compactado = {}
    
    # Obter valores de tabelas de tabelas_query (valores do dicion√°rio)
    tabelas_query_values = list(tabelas_query.values())
    
    # Unir todas as colunas de colunas_query em um √∫nico conjunto
    todas_colunas = set()
    for cols in colunas_query.values():
        todas_colunas.update(col.upper() for col in cols)
    
    # Debug
    print(f"Tabelas para busca: {tabelas_query_values}")
    print(f"Colunas para busca: {todas_colunas}")
    
    # Para cada item nos resultados filtrados
    for item in resultados_filtrados:
        tipo_registro = item.get("tipo", "")
        tabela_oc3 = item.get("TABELA OC3 LIGHT", "").upper()
        tabela_dm = item.get("TABELA DATA MESH", "")
        coluna_oc3 = item.get("CAMPO OC3 LIGHT", "").lower()
        coluna_dm = item.get("CAMPO DATA MESH FINAL", "")
        tipo_dado = item.get("TIPO DE DADO", "")
        
        # Verificar se a tabela est√° presente nas tabelas da query
        # Usar uma correspond√™ncia mais flex√≠vel
        tabela_match = False
        for tabela_query in tabelas_query_values:
            if tabela_oc3 in tabela_query or tabela_query in tabela_oc3:
                tabela_match = True
                break
                
        if tabela_match:
            if tabela_oc3 not in json_compactado:
                json_compactado[tabela_oc3] = {}
                
            if tabela_dm not in json_compactado[tabela_oc3]:
                json_compactado[tabela_oc3][tabela_dm] = {}
                
            json_compactado[tabela_oc3][tabela_dm][coluna_oc3.lower()] = {
                "tabela_data_mesh": tabela_dm,
                "campo_data_mesh": coluna_dm,
                "tipo_de_dado": tipo_dado,
                "tipo": tipo_registro
            }
    
    # Debug
    print(f"JSON compactado gerado para {len(json_compactado)} tabelas")
    for tabela in json_compactado:
        print(f"  Tabela {tabela}: {len(json_compactado[tabela])} mapeamentos")
    
    return json_compactado

def retorna_selecao_de_tabelas_para_usuario(tabelas_alias_map, colunas_usadas, mapeamento_tabelas_oc3_para_mesh_total):
    """
    Retorna uma sele√ß√£o de tabelas para o usu√°rio com base nos mapeamentos dispon√≠veis.
    """
    tabelas_match = {}
    
    print("Processando sele√ß√£o de tabelas para o usu√°rio...")
    print(f"Tabelas e aliases: {tabelas_alias_map}")
    print(f"Colunas usadas: {colunas_usadas}")
    
    # Para cada alias e tabela_oc3 no mapeamento
    for alias, tabela_oc3 in tabelas_alias_map.items():
        tabelas_match[tabela_oc3] = {}
        
        # Se o alias existe nas colunas usadas
        if alias in colunas_usadas:
            # Para cada coluna do alias
            for coluna_oc3 in colunas_usadas[alias]:
                # Verificar se a tabela_oc3 existe no mapeamento_tabelas_oc3_para_mesh_total
                for tab_oc3 in mapeamento_tabelas_oc3_para_mesh_total:
                    # Correspond√™ncia flex√≠vel para tabelas
                    if tab_oc3.upper() in tabela_oc3.upper() or tabela_oc3.upper() in tab_oc3.upper():
                        # Verificar se a coluna existe no mapeamento para essa tabela
                        for tab_dm, campos in mapeamento_tabelas_oc3_para_mesh_total[tab_oc3].items():
                            for col_oc3, dados in campos.items():
                                # Correspond√™ncia flex√≠vel para colunas
                                if col_oc3.lower() == coluna_oc3.lower() or col_oc3.lower() in coluna_oc3.lower() or coluna_oc3.lower() in col_oc3.lower():
                                    if coluna_oc3 not in tabelas_match[tabela_oc3]:
                                        tabelas_match[tabela_oc3][coluna_oc3] = []
                                    tabelas_match[tabela_oc3][coluna_oc3].append({**dados, "sigla": alias})
    
    # Se n√£o houver correspond√™ncias, tentar buscar por colunas "sem_alias"
    if all(len(colunas) == 0 for colunas in tabelas_match.values()) and "sem_alias" in colunas_usadas:
        print("Tentando buscar correspond√™ncias para colunas sem alias...")
        # Buscar correspond√™ncias para colunas sem alias
        for tabela_oc3 in tabelas_match:
            for coluna_sem_alias in colunas_usadas["sem_alias"]:
                for tab_oc3 in mapeamento_tabelas_oc3_para_mesh_total:
                    if tab_oc3.upper() in tabela_oc3.upper() or tabela_oc3.upper() in tab_oc3.upper():
                        for tab_dm, campos in mapeamento_tabelas_oc3_para_mesh_total[tab_oc3].items():
                            for col_oc3, dados in campos.items():
                                if col_oc3.upper() == coluna_sem_alias or col_oc3.upper() in coluna_sem_alias or coluna_sem_alias in col_oc3.upper():
                                    if coluna_sem_alias not in tabelas_match[tabela_oc3]:
                                        tabelas_match[tabela_oc3][coluna_sem_alias] = []
                                    tabelas_match[tabela_oc3][coluna_sem_alias].append({**dados, "sigla": "sem_alias"})
    
    # Verificar se h√° algum mapeamento dispon√≠vel
    mapeamentos_disponiveis = any(len(colunas) > 0 for tabela, colunas in tabelas_match.items())
    if not mapeamentos_disponiveis:
        print("ATEN√á√ÉO: Nenhum mapeamento dispon√≠vel para sele√ß√£o!")
        
        # Tentativa de fallback - usar todos os mapeamentos dispon√≠veis
        for tabela_oc3 in tabelas_alias_map.values():
            for tab_oc3 in mapeamento_tabelas_oc3_para_mesh_total:
                if tab_oc3.upper() in tabela_oc3.upper() or tabela_oc3.upper() in tab_oc3.upper():
                    tabelas_match[tabela_oc3] = {}
                    for tab_dm, campos in mapeamento_tabelas_oc3_para_mesh_total[tab_oc3].items():
                        for col_oc3, dados in campos.items():
                            if col_oc3 not in tabelas_match[tabela_oc3]:
                                tabelas_match[tabela_oc3][col_oc3] = []
                            tabelas_match[tabela_oc3][col_oc3].append({**dados, "sigla": "fallback"})
        
        # Verificar novamente se h√° mapeamentos dispon√≠veis ap√≥s o fallback
        mapeamentos_disponiveis = any(len(colunas) > 0 for tabela, colunas in tabelas_match.items())
        if not mapeamentos_disponiveis:
            print("FALLBACK: Adicionando todos os mapeamentos dispon√≠veis")
            # √öltimo recurso: adicionar todas as tabelas e colunas dos mapeamentos
            for tab_oc3, mapeamento in mapeamento_tabelas_oc3_para_mesh_total.items():
                tabelas_match[tab_oc3] = {}
                for tab_dm, campos in mapeamento.items():
                    for col_oc3, dados in campos.items():
                        if col_oc3 not in tabelas_match[tab_oc3]:
                            tabelas_match[tab_oc3][col_oc3] = []
                        tabelas_match[tab_oc3][col_oc3].append({**dados, "sigla": "fallback_all"})
    
    return tabelas_match

def registrar_mapeamento_usuario(tabelas_alias_map, colunas_usadas, mapeamento_tabelas_oc3_para_mesh_filtrado):
    """
    Registra o mapeamento selecionado pelo usu√°rio.
    """
    tabelas_mapeadas = {}
    
    # Debug do objeto mapeamento_tabelas_oc3_para_mesh_filtrado
    print(f"Tipo de mapeamento_tabelas_oc3_para_mesh_filtrado: {type(mapeamento_tabelas_oc3_para_mesh_filtrado)}")
    
    # Se n√£o h√° tabelas para mapear, retornar dicion√°rio vazio
    if not mapeamento_tabelas_oc3_para_mesh_filtrado:
        print("Aviso: Nenhum mapeamento filtrado dispon√≠vel")
        return {}  # Retorna um dicion√°rio vazio, n√£o uma lista vazia

    # Para cada tabela e suas colunas no mapeamento
    for tabela_oc3, colunas in mapeamento_tabelas_oc3_para_mesh_filtrado.items():
        if colunas:  # Verificar se h√° colunas para esta tabela
            tabelas_mapeadas[tabela_oc3] = {}
            
            # Para cada coluna e seus mapeamentos
            for coluna_oc3, mapeamentos in colunas.items():
                if mapeamentos:  # Verificar se h√° mapeamentos para esta coluna
                    # Se houver mais de um mapeamento poss√≠vel, pedir ao usu√°rio para selecionar
                    if len(mapeamentos) > 1:
                        print(f"Mais de 1 correspond√™ncia OC3 -> Mesh para tabela {tabela_oc3} - coluna {coluna_oc3}")
                        for i, mapeamento in enumerate(mapeamentos):
                            print(f"[{i}]: {mapeamento.get('tabela_data_mesh', 'N/A')} - {mapeamento.get('campo_data_mesh', 'N/A')}")
                        
                        # Solicitar sele√ß√£o do usu√°rio
                        try:
                            print("Digite o √≠ndice desejado:")
                            indice = int(input())
                            if 0 <= indice < len(mapeamentos):
                                tabelas_mapeadas[tabela_oc3][coluna_oc3] = mapeamentos[indice]
                            else:
                                print(f"√çndice inv√°lido. Usando o primeiro mapeamento.")
                                tabelas_mapeadas[tabela_oc3][coluna_oc3] = mapeamentos[0]
                        except (ValueError, IndexError):
                            print("Entrada inv√°lida ou √≠ndice fora de alcance. Usando o primeiro mapeamento.")
                            tabelas_mapeadas[tabela_oc3][coluna_oc3] = mapeamentos[0]
                    else:
                        # Se houver apenas um mapeamento, use-o automaticamente
                        tabelas_mapeadas[tabela_oc3][coluna_oc3] = mapeamentos[0]
                else:
                    print(f"Sem correspond√™ncia OC3 -> Mesh para tabela {tabela_oc3} - coluna {coluna_oc3}")
                    tabelas_mapeadas[tabela_oc3][coluna_oc3] = {"mensagem": "Sem correspond√™ncia"}
    
    # Debug do objeto final
    print(f"Tipo do objeto retornado por registrar_mapeamento_usuario: {type(tabelas_mapeadas)}")
    print(f"Conte√∫do (primeiras chaves): {list(tabelas_mapeadas.keys())[:5] if tabelas_mapeadas else 'vazio'}")
    
    return tabelas_mapeadas  # Retorna um dicion√°rio, n√£o uma lista

def processar_query(query, resultados_filtrados):
    """
    Processa a query SQL para extrair tabelas, colunas e mapeamentos.
    """
    # Extrair tabelas e aliases
    tabelas_alias_map = extrair_tabelas_aliases(query)
    
    # Se n√£o foram encontradas tabelas, tentar abordagem alternativa
    if not tabelas_alias_map:
        print("ALERTA: Nenhuma tabela extra√≠da pelo m√©todo padr√£o. Tentando abordagem alternativa...")
        # Extrair todas as tabelas mencionadas na query
        tabelas = re.findall(r"(?:FROM|JOIN)\s+(\w+(?:\.\w+)?)", query, re.IGNORECASE)
        for i, tabela in enumerate(tabelas):
            # Remover prefixos de schema se existirem
            if "." in tabela:
                _, tabela = tabela.split(".", 1)
            # Usar um alias padr√£o baseado no √≠ndice
            alias = f"t{i}"
            tabelas_alias_map[alias] = tabela.upper()
        
        print(f"Tabelas extra√≠das com abordagem alternativa: {tabelas_alias_map}")
    
    # Extrair colunas usadas na query
    colunas_usadas = extrair_colunas_usadas(query, resultados_filtrados)
    
    # Compactar os resultados filtrados em um formato mais eficiente
    json_compactados = compactar_json(resultados_filtrados, tabelas_alias_map, colunas_usadas)
    
    # Retornar sele√ß√£o de tabelas para o usu√°rio
    mapeamentos_tabelas_oc3_para_mesh_filtrado = retorna_selecao_de_tabelas_para_usuario(
        tabelas_alias_map, colunas_usadas, json_compactados)
    
    # Registrar mapeamento selecionado pelo usu√°rio
    tabelas_mapeadas_usuario = registrar_mapeamento_usuario(
        tabelas_alias_map, colunas_usadas, mapeamentos_tabelas_oc3_para_mesh_filtrado)
    
    # Validar o formato de retorno
    if not isinstance(tabelas_mapeadas_usuario, dict):
        print(f"ERRO: Formato de retorno incorreto. Esperado dict, obtido {type(tabelas_mapeadas_usuario)}")
        # For√ßar retorno como dicion√°rio para evitar erros
        return {}
    
    # Embrulhar o dicion√°rio em uma lista para manter compatibilidade
    print(f"Retornando mapeamento como dicion√°rio dentro de uma lista")
    return [tabelas_mapeadas_usuario]  # Retorna como lista contendo um dicion√°rio


=================================================================================================
query_validator

import os
import sys
import re
import sqlparse

# Conjunto de palavras-chave reservadas comuns em SQL
SQL_RESERVED_KEYWORDS = {
    "ALL", "ALTER", "AND", "AS", "BETWEEN", "BY", "CASE", "CAST", "CREATE", "CROSS", "DELETE", "DISTINCT", "DROP",
    "ELSE", "END", "EXISTS", "FALSE", "FOR", "FROM", "FULL", "GROUP", "HAVING", "IN", "INNER", "INSERT", "INTERSECT",
    "IS", "JOIN", "LEFT", "LIKE", "LIMIT", "NOT", "NULL", "ON", "ORDER", "OUTER", "RIGHT", "SELECT",
    "SET", "TABLE", "THEN", "TRUE", "UNION", "UPDATE", "USING", "VALUES", "WHERE", "WITH"
}

def validar_query(query):
    """Valida uma query SQL de forma gen√©rica."""
    print("Fun√ß√£o validar query chamada")

    # 1. Verifica√ß√£o sint√°tica
    try:
        parsed_query = sqlparse.parse(query)
        if not parsed_query:
            return {"status": "Erro", "mensagem": "A query est√° vazia ou mal formatada."}
    except Exception as e:
        return {"status": "Erro", "mensagem": f"Erro ao analisar a query: {e}"}

    # 2. Verificar palavras-chave reservadas n√£o escapadas
    tokens = set(re.findall(r"\b[A-Za-z_]+\b", query.upper()))
    print("Tokens encontrados:", tokens)
    invalid_tokens = [token for token in tokens if token in SQL_RESERVED_KEYWORDS and f"`{token}`" not in query]
    contextually_valid_tokens = {"SELECT", "FROM", "WHERE", "AND", "JOIN", "ON", "AS", "BETWEEN", "GROUP", "BY",
                                 "WITH", "HAVING", "ORDER", "INNER", "LEFT", "IN"}
    invalid_tokens = [token for token in invalid_tokens if token not in contextually_valid_tokens]
    print("Tokens inv√°lidos:", invalid_tokens)

    if invalid_tokens:
        return {"status": "Erro", "mensagem": f"Palavras-chave reservadas precisam ser escapadas com acentos graves: {invalid_tokens}"}

    # 3. Validar estrutura b√°sica
    if not re.search(r"SELECT\s", query, re.IGNORECASE):
        return {"status": "Erro", "mensagem": "Query inv√°lida: falta a cl√°usula SELECT"}
    if not re.search(r"FROM\s", query, re.IGNORECASE):
        return {"status": "Erro", "mensagem": "Query inv√°lida: falta a cl√°usula FROM"}

    # 4. Validar tabelas e colunas
    tabelas = re.findall(r"(?:FROM|JOIN)\s+(\S+)", query, re.IGNORECASE)
    colunas = re.findall(r"SELECT\s+(.*?)\s+FROM", query, re.IGNORECASE | re.DOTALL)
    print("Tabelas encontradas:", tabelas)
    print("Colunas encontradas antes do split:", colunas)

    if colunas:
        # Ajuste para lidar com colunas complexas e fun√ß√µes
        colunas = [col.strip() for col in re.split(r",\s*(?![^(]*\))", colunas[0]) if col.strip()]
        print("Colunas encontradas ap√≥s o split:", colunas)

    if not tabelas:
        return {"status": "Erro", "mensagem": "Nenhuma tabela encontrada na Query"}
    if not colunas:
        return {"status": "Erro", "mensagem": "Nenhuma coluna encontrada na Query"}

    # Se passou por todas as valida√ß√µes
    return {"status": "Sucesso", "mensagem": "A query √© v√°lida"}

def lambda_handler(event, _context):
    """Fun√ß√£o Lambda para processar a query"""
    query = sys.stdin.read()  # L√™ a query da entrada padr√£o
    if not query:
        return {"error": "Nenhuma query informada"}

    resultado_sql = validar_query(query)
    print(resultado_sql)
    return resultado_sql

# Chamada da fun√ß√£o Lambda
if __name__ == "__main__":
    lambda_handler(None, None)


=================================================================================================
sac_oc3

"""
M√≥dulo para convers√£o de queries SAC OC3 para DataMesh.
Este m√≥dulo cont√©m fun√ß√µes para carregar mapeamentos SAC OC3 e
converter queries SQL do formato SAC para o formato DataMesh.
"""

import os
import json
import logging
import re
import time
from typing import List, Dict, Any

# Configurar logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

def carregar_mapeamentos_sac(pasta_json: str) -> List[Dict[str, Any]]:
    """
    Carrega e normaliza mapeamentos SAC OC3 de uma pasta espec√≠fica.
    
    :param pasta_json: Caminho para a pasta com arquivos JSON de mapeamento SAC.
    :return: Lista de mapeamentos normalizados no formato padr√£o.
    """
    logger.info(f"Carregando mapeamentos SAC OC3 da pasta: {pasta_json}")
    mapeamentos_normalizados = []
    
    # Verificar se a pasta existe
    if not os.path.isdir(pasta_json):
        logger.error(f"Pasta de mapeamentos SAC n√£o encontrada: {pasta_json}")
        return []
    
    # Percorrer arquivos na pasta
    for arquivo in os.listdir(pasta_json):
        if arquivo.endswith('.json'):
            caminho_completo = os.path.join(pasta_json, arquivo)
            
            try:
                # Carregar o arquivo JSON
                with open(caminho_completo, 'r', encoding='utf-8') as f:
                    dados = json.load(f)
                
                # Verificar se segue o formato esperado do SAC OC3
                if "aba" in dados and "tabelas" in dados:
                    logger.info(f"Processando arquivo de mapeamento SAC: {arquivo}")
                    mapeamentos_normalizados.extend(normalizar_mapeamentos_sac(dados))
                else:
                    logger.warning(f"Arquivo n√£o segue o formato SAC OC3: {arquivo}")
            
            except Exception as e:
                logger.error(f"Erro ao processar arquivo {arquivo}: {str(e)}")
    
    logger.info(f"Total de mapeamentos SAC normalizados: {len(mapeamentos_normalizados)}")
    return mapeamentos_normalizados

def normalizar_mapeamentos_sac(dados_sac: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Normaliza os dados do formato SAC OC3 para o formato padr√£o de mapeamento.
    
    :param dados_sac: Dicion√°rio com dados no formato SAC OC3.
    :return: Lista de mapeamentos normalizados.
    """
    mapeamentos = []
    
    for tabela in dados_sac.get("tabelas", []):
        tabela_nome = tabela.get("tabela", "")
        tipo_tabela = tabela.get("tipo", "")
        
        # Verificar se √© uma tabela v√°lida
        if not tabela_nome:
            continue
        
        # Determinar o tipo (cadastro ou hub)
        tipo_normalizado = "cadastro" if tipo_tabela == "conversaoatl" else "hub"
        
        # Remover prefixo tbpli_ do nome da tabela
        tabela_datamesh = tabela_nome.replace("tbpli_", "")
        
        # Processar campos da tabela
        for campo in tabela.get("campos", []):
            nome_campo = campo.get("campo", "")
            tipo_campo = campo.get("tipoCampo", "")
            tamanho = campo.get("tam", "")
            descricao = campo.get("descri√ß√£o", "")
            
            # Pular √≠ndices e campos compostos
            if "clustered" in nome_campo or "," in nome_campo or not tipo_campo:
                continue
            
            # Normalizar nome de campo para DataMesh
            nome_campo_datamesh = normalizar_nome_campo(nome_campo)
            
            # Mapear tipo de dado
            tipo_dado_datamesh = mapear_tipo_dado(tipo_campo, tamanho)
            
            # Criar mapeamento normalizado
            mapeamento = {
                "tipo": tipo_normalizado,
                "TABELA OC3 LIGHT": tabela_nome,
                "TABELA DATA MESH": tabela_datamesh,
                "CAMPO OC3 LIGHT": nome_campo,
                "CAMPO DATA MESH FINAL": nome_campo_datamesh,
                "TIPO DE DADO": tipo_dado_datamesh
            }
            
            mapeamentos.append(mapeamento)
    
    return mapeamentos

def normalizar_nome_campo(nome_campo: str) -> str:
    """
    Normaliza o nome de um campo do formato SAC OC3 para o formato DataMesh.
    
    :param nome_campo: Nome do campo no formato SAC OC3.
    :return: Nome do campo normalizado.
    """
    # Remover qualquer indica√ß√£o de tipo entre par√™nteses
    if "(" in nome_campo:
        nome_campo = nome_campo.split("(")[0].strip()
    
    # Mapeamento de prefixos padr√£o
    prefixos = {
        "cd_": "codigo_",
        "dt_": "data_",
        "vl_": "valor_",
        "qt_": "quantidade_",
        "nr_": "numero_",
        "ic_": "indicador_",
        "ds_": "descricao_",
        "tp_": "tipo_",
        "id_": "id_"
    }
    
    # Aplicar mapeamento de prefixos
    for prefixo_original, prefixo_novo in prefixos.items():
        if nome_campo.startswith(prefixo_original):
            resto_nome = nome_campo[len(prefixo_original):]
            
            # Converter CamelCase para snake_case
            resultado = prefixo_novo
            for i, char in enumerate(resto_nome):
                if char.isupper() and i > 0:
                    resultado += "_" + char.lower()
                else:
                    resultado += char.lower()
            
            return resultado
    
    # Se n√£o tem prefixo conhecido, apenas converter CamelCase para snake_case
    resultado = ""
    for i, char in enumerate(nome_campo):
        if char.isupper() and i > 0:
            resultado += "_" + char.lower()
        else:
            resultado += char.lower()
    
    return resultado

def mapear_tipo_dado(tipo_campo: str, tamanho: str) -> str:
    """
    Mapeia um tipo de dado do formato SAC OC3 para o formato DataMesh.
    
    :param tipo_campo: Tipo de campo no formato SAC OC3.
    :param tamanho: Tamanho do campo.
    :return: Tipo de dado no formato DataMesh.
    """
    # Extrair o tipo base sem par√™nteses
    tipo_base = tipo_campo.lower()
    if "(" in tipo_base:
        tipo_base = tipo_base.split("(")[0].strip()
    
    # Mapeamento de tipos b√°sicos
    mapeamento_tipos = {
        "cd_sistema": "INT",
        "tinyint": "TINYINT",
        "smallint": "SMALLINT",
        "int": "INT",
        "bigint": "BIGINT",
        "decimal": f"DECIMAL({tamanho or '18,2'})",
        "numeric": f"DECIMAL({tamanho or '18,2'})",
        "float": "FLOAT",
        "real": "FLOAT",
        "money": "DECIMAL(19,4)",
        "smallmoney": "DECIMAL(10,4)",
        "char": f"CHAR({tamanho or '1'})",
        "nchar": f"CHAR({tamanho or '1'})",
        "varchar": f"VARCHAR({tamanho or '255'})",
        "nvarchar": f"VARCHAR({tamanho or '255'})",
        "text": "TEXT",
        "ntext": "TEXT",
        "datetime": "DATE",
        "smalldatetime": "DATE",
        "date": "DATE",
        "time": "TIME",
        "bit": "BOOLEAN",
        "binary": f"BINARY({tamanho or '50'})",
        "varbinary": f"VARBINARY({tamanho or '50'})",
        "image": "BINARY(MAX)",
        "uniqueidentifier": "VARCHAR(36)"
    }
    
    return mapeamento_tipos.get(tipo_base, f"VARCHAR({tamanho or '255'})")

def extrair_tabelas_aliases_sac(query: str) -> Dict[str, str]:
    """
    Extrai tabelas e seus aliases de uma query SAC OC3.
    
    :param query: Query SQL no formato SAC OC3.
    :return: Dicion√°rio com {alias: tabela}.
    """
    # Padr√£o para buscar tabelas com alias
    padrao = r"(tbpli_\w+)\s+(?:AS\s+)?(\w+)"
    
    # Buscar todas as ocorr√™ncias
    matches = re.findall(padrao, query, re.IGNORECASE)
    
    # Construir dicion√°rio {alias: tabela}
    alias_tabela = {}
    for tabela, alias in matches:
        alias_tabela[alias] = tabela
    
    # Buscar tabelas sem alias (usar a pr√≥pria tabela como chave)
    padrao_sem_alias = r"FROM\s+(tbpli_\w+)(?!\s+\w+)"
    matches_sem_alias = re.findall(padrao_sem_alias, query, re.IGNORECASE)
    
    for tabela in matches_sem_alias:
        alias_tabela[tabela] = tabela
    
    return alias_tabela

def extrair_colunas_usadas_sac(query: str, tabelas_aliases: Dict[str, str]) -> Dict[str, set]:
    """
    Extrai colunas usadas em uma query SAC OC3.
    
    :param query: Query SQL no formato SAC OC3.
    :param tabelas_aliases: Dicion√°rio com {alias: tabela}.
    :return: Dicion√°rio com {alias: set(colunas)}.
    """
    colunas_por_alias = {}
    
    # Inicializar conjuntos para cada alias
    for alias in tabelas_aliases.keys():
        colunas_por_alias[alias] = set()
    
    # Padr√£o para buscar colunas com alias (alias.coluna)
    for alias in tabelas_aliases.keys():
        padrao = rf"{alias}\.(\w+)"
        matches = re.findall(padrao, query, re.IGNORECASE)
        
        for coluna in matches:
            colunas_por_alias[alias].add(coluna)
    
    # Padr√£o para colunas sem alias
    # Isso √© mais complexo e pode gerar falsos positivos
    # Uma solu√ß√£o simples √© verificar palavras que come√ßam com prefixos comuns
    prefixos = ["cd_", "dt_", "vl_", "qt_", "nr_", "ic_", "ds_", "tp_", "id_"]
    
    # Extrair todas as palavras da query
    palavras = re.findall(r"\b(\w+)\b", query)
    
    # Buscar palavras que come√ßam com prefixos comuns
    for palavra in palavras:
        for prefixo in prefixos:
            if palavra.lower().startswith(prefixo.lower()):
                # Adicionar a coluna a uma chave especial "sem_alias"
                if "sem_alias" not in colunas_por_alias:
                    colunas_por_alias["sem_alias"] = set()
                colunas_por_alias["sem_alias"].add(palavra)
    
    return colunas_por_alias

def compactar_mapeamentos_sac(mapeamentos: List[Dict[str, Any]], tabelas_aliases: Dict[str, str], 
                             colunas_por_alias: Dict[str, set]) -> Dict[str, Dict[str, Dict[str, Any]]]:
    """
    Compacta os mapeamentos SAC OC3 para um formato mais f√°cil de usar.
    
    :param mapeamentos: Lista de mapeamentos normalizados.
    :param tabelas_aliases: Dicion√°rio com {alias: tabela}.
    :param colunas_por_alias: Dicion√°rio com {alias: set(colunas)}.
    :return: Dicion√°rio com mapeamentos compactados.
    """
    # Inverter tabelas_aliases para {tabela: alias}
    tabelas = {}
    for alias, tabela in tabelas_aliases.items():
        if tabela not in tabelas:
            tabelas[tabela] = []
        tabelas[tabela].append(alias)
    
    # Construir mapeamento compactado
    mapeamento_compactado = {}
    
    # Para cada tabela na query
    for tabela, aliases in tabelas.items():
        # Inicializar tabela no mapeamento
        if tabela not in mapeamento_compactado:
            mapeamento_compactado[tabela] = {}
        
        # Buscar mapeamentos para esta tabela
        for m in mapeamentos:
            if m["TABELA OC3 LIGHT"] == tabela:
                tabela_dm = m["TABELA DATA MESH"]
                
                # Inicializar tabela DataMesh no mapeamento
                if tabela_dm not in mapeamento_compactado[tabela]:
                    mapeamento_compactado[tabela][tabela_dm] = {}
                
                # Adicionar colunas mapeadas
                coluna_oc3 = m["CAMPO OC3 LIGHT"]
                
                # Verificar se a coluna √© usada na query
                coluna_usada = False
                for alias in aliases:
                    if alias in colunas_por_alias and coluna_oc3 in colunas_por_alias[alias]:
                        coluna_usada = True
                        break
                
                # Se a coluna estiver na lista "sem_alias", tamb√©m considerar
                if "sem_alias" in colunas_por_alias and coluna_oc3 in colunas_por_alias["sem_alias"]:
                    coluna_usada = True
                
                # Adicionar mapeamento se a coluna for usada
                if coluna_usada:
                    mapeamento_compactado[tabela][tabela_dm][coluna_oc3] = {
                        "tabela_data_mesh": tabela_dm,
                        "campo_data_mesh": m["CAMPO DATA MESH FINAL"],
                        "tipo_de_dado": m["TIPO DE DADO"],
                        "tipo": m["tipo"]
                    }
    
    return mapeamento_compactado

def processar_query_sac(query: str, mapeamentos: List[Dict[str, Any]], modo_automatico: bool = False) -> List[Dict[str, Any]]:
    """
    Processa uma query SAC OC3 e permite sele√ß√£o de mapeamentos.
    
    :param query: Query SQL no formato SAC OC3.
    :param mapeamentos: Lista de mapeamentos normalizados.
    :param modo_automatico: Se True, seleciona automaticamente a primeira op√ß√£o.
    :return: Lista de mapeamentos selecionados.
    """
    # Extrair tabelas e aliases
    tabelas_aliases = extrair_tabelas_aliases_sac(query)
    logger.info(f"Tabelas e aliases extra√≠dos: {tabelas_aliases}")
    
    # Extrair colunas usadas
    colunas_por_alias = extrair_colunas_usadas_sac(query, tabelas_aliases)
    logger.info(f"Colunas extra√≠das: {colunas_por_alias}")
    
    # Compactar mapeamentos
    mapeamentos_compactados = compactar_mapeamentos_sac(mapeamentos, tabelas_aliases, colunas_por_alias)
    
    # Permitir sele√ß√£o pelo usu√°rio quando houver m√∫ltiplas op√ß√µes
    resultado_final = []
    
    logger.info("\nSele√ß√£o de mapeamentos para a query SAC OC3:")
    
    # Para cada tabela na query
    for tabela_oc3, mapeamentos_tabela in mapeamentos_compactados.items():
        logger.info(f"\nTabela: {tabela_oc3}")
        
        # Se houver mais de uma op√ß√£o de tabela DataMesh
        if len(mapeamentos_tabela) > 1 and not modo_automatico:
            logger.info("M√∫ltiplas op√ß√µes de mapeamento para esta tabela:")
            opcoes = list(mapeamentos_tabela.keys())
            
            for i, opcao in enumerate(opcoes):
                logger.info(f"  [{i}] {opcao}")
            
            # Solicitar escolha ao usu√°rio
            try:
                escolha = input("Selecione o n√∫mero da op√ß√£o desejada: ")
                indice = int(escolha)
                tabela_dm_escolhida = opcoes[indice]
            except (ValueError, IndexError, EOFError):
                logger.warning("Op√ß√£o inv√°lida ou entrada n√£o dispon√≠vel, usando a primeira op√ß√£o.")
                tabela_dm_escolhida = opcoes[0]
        else:
            # Verificar se existem mapeamentos dispon√≠veis para esta tabela
            if not mapeamentos_tabela:
                logger.warning(f"AVISO: Nenhum mapeamento encontrado para a tabela {tabela_oc3}. Pulando esta tabela.")
                continue  # Pula para a pr√≥xima tabela
            tabela_dm_escolhida = list(mapeamentos_tabela.keys())[0]
        
        logger.info(f"Tabela DataMesh selecionada: {tabela_dm_escolhida}")
        
        # Para cada campo mapeado nesta tabela
        for campo_oc3, info_campo in mapeamentos_tabela[tabela_dm_escolhida].items():
            # Adicionar ao resultado final
            mapeamento = {
                "tipo": info_campo["tipo"],
                "TABELA OC3 LIGHT": tabela_oc3,
                "TABELA DATA MESH": tabela_dm_escolhida,
                "CAMPO OC3 LIGHT": campo_oc3,
                "CAMPO DATA MESH FINAL": info_campo["campo_data_mesh"],
                "TIPO DE DADO": info_campo["tipo_de_dado"]
            }
            resultado_final.append(mapeamento)
    
    logger.info(f"\nTotal de mapeamentos selecionados: {len(resultado_final)}")
    return resultado_final


def converter_query_sac_para_datamesh(bedrock_runtime, query: str, mapeamentos: List[Dict[str, Any]], modo_automatico: bool = False) -> str:
    """
    Converte uma query SQL do formato SAC OC3 para o formato DataMesh usando Claude.
    
    :param bedrock_runtime: Cliente do AWS Bedrock para chamadas ao Claude.
    :param query: Query SQL no formato SAC OC3.
    :param mapeamentos: Lista de mapeamentos normalizados.
    :param modo_automatico: Se True, seleciona automaticamente a primeira op√ß√£o de mapeamento.
    :return: Query SQL convertida para o formato DataMesh.
    """
    try:
        # Processar a query para sele√ß√£o de mapeamentos
        mapeamentos_selecionados = processar_query_sac(query, mapeamentos, modo_automatico)
        
        # Construir instru√ß√µes espec√≠ficas para SAC OC3
        instrucoes = """
        Voc√™ √© um assistente especializado em convers√£o de queries SQL do formato SAC OC3 para o formato DataMesh.
        
        INSTRU√á√ïES ESPEC√çFICAS PARA CONVERS√ÉO DE SAC OC3:
        
        1. Tabelas com prefixo 'tbpli_' no SAC OC3 devem ser convertidas para o formato DataMesh:
           - Para tabelas do tipo 'cadastro', adicione o prefixo 'spec_'
           - Para tabelas do tipo 'hub', adicione o prefixo 'hub_'
           - Remova o prefixo 'tbpli_' original
        
        2. Nomes de campos seguem estas regras de convers√£o:
           - 'cd_' se torna 'codigo_'
           - 'dt_' se torna 'data_'
           - 'vl_' se torna 'valor_'
           - 'qt_' se torna 'quantidade_'
           - 'ic_' se torna 'indicador_'
           - 'ds_' se torna 'descricao_'
           - 'tp_' se torna 'tipo_'
           - 'nr_' se torna 'numero_'
           - Formato CamelCase se torna snake_case (ex: NomeCliente -> nome_cliente)
        
        3. Campos de data (dt_) devem usar CAST(campo AS DATE)
        
        4. Utilize o mapeamento exato fornecido para cada tabela e campo
        
        5. Retorne APENAS a query SQL convertida, sem explica√ß√µes
        
        6. Mantenha a l√≥gica da query original, incluindo all joins, where clauses, etc.
        
        7. Mantenha aliases de tabela e de campo originais
        """
        
        # Calcular tokens baseado no tamanho da query e mapeamentos
        max_tokens = min(2500, 500 + len(query) // 2 + len(mapeamentos_selecionados) * 10)
        
        payload = {
            "anthropic_version": "bedrock-2023-05-31",
            "messages": [
                {
                    "role": "user",
                    "content": f"{instrucoes}\n\nQuery original (SAC OC3): {query}\n\nJSON Mapeamentos (DE-PARA): {json.dumps(mapeamentos_selecionados)}"
                }
            ],
            "max_tokens": max_tokens
        }
        
        # EXIBIR PAYLOAD EM VEZ DE CHAMAR BEDROCK
        print("\n" + "=" * 80)
        print("PAYLOAD QUE SERIA ENVIADO AO BEDROCK:")
        print("=" * 80)
        print(json.dumps(payload, indent=2))
        print("=" * 80)
        
        # Retorna uma resposta simulada
        return """SELECT
    f.codigo_sistema,
    CAST(f.data_feriado AS DATE),
    f.descricao_feriado,
    f.tipo_feriado,
    f.id_local,
    c.codigo_classificacao,
    c.descricao_classificacao,
    c.indicador_vinculo
FROM
    spec_Feriado f
JOIN
    spec_classificacaoFundo c ON f.codigo_sistema = c.codigo_sistema
LEFT JOIN
    spec_FundoParametro p ON p.codigo_sistema = c.codigo_sistema
WHERE
    f.data_feriado BETWEEN '2023-01-01' AND '2023-12-31'
    AND f.tipo_feriado = 'N'
    AND c.indicador_vinculo = 'S'
GROUP BY
    f.codigo_sistema,
    f.data_feriado,
    f.descricao_feriado,
    f.tipo_feriado,
    f.id_local,
    c.codigo_classificacao,
    c.descricao_classificacao,
    c.indicador_vinculo
ORDER BY
    f.data_feriado, c.codigo_classificacao"""
    
    except Exception as e:
        logger.error(f"Erro ao converter query SAC OC3: {str(e)}", exc_info=True)
        return f"Erro ao processar a query: {str(e)}"
# Para testes e debug
if __name__ == "__main__":
    # Exemplo de uso
    pasta_mapeamentos = "./mapeamentos-sac"
    mapeamentos = carregar_mapeamentos_sac(pasta_mapeamentos)
    
    # Exibir alguns exemplos para verifica√ß√£o
    for i, m in enumerate(mapeamentos[:5]):
        print(f"Mapeamento {i+1}:")
        print(f"  Tabela OC3: {m['TABELA OC3 LIGHT']}")
        print(f"  Tabela DM: {m['TABELA DATA MESH']}")
        print(f"  Campo OC3: {m['CAMPO OC3 LIGHT']}")
        print(f"  Campo DM: {m['CAMPO DATA MESH FINAL']}")
        print(f"  Tipo: {m['TIPO DE DADO']}")
        print()

=================================================================================================
utils

import logging

def setup_logger() -> logging.Logger:
    """
    Configura o logger com n√≠vel de informa√ß√£o e formato padr√£o.

    :return: Logger configurado.
    """
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
    return logging.getLogger(__name__)

logger = setup_logger()

